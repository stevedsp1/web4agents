---
title: robots.txt
slug: robotstxt
type: standard
description: Fichier standard qui indique aux crawlers et aux agents quels chemins ils peuvent ou non accéder.
category: agent-facing
publishedAt: '2025-02-01'
updatedAt: '2025-02-15'
status: published
website: 'https://developers.google.com/search/docs/crawling-indexing/robots/robots_txt'
relatedTerms:
  - geo
  - llm-indexing
---

## Définition

**robots.txt** est un fichier texte à `/robots.txt` qui indique aux crawlers et bots quelles URL ils sont autorisés ou non à demander. Il est utilisé par les moteurs de recherche et, de plus en plus, par les crawlers IA (ex. GPTBot, ClaudeBot).

## Pertinence pour la GEO

Un robots.txt correct fait partie de la GEO : il définit le contrat de crawl pour les agents. Le combiner avec llms.txt et les données structurées donne aux agents une vision claire de ce qu’ils peuvent accéder et comment utiliser votre site.

## Voir aussi

Lié : GEO, LLM Indexing.
